{
  "name": "test",
  "pinned": false,
  "createdAt": 1738533873461,
  "preset": "",
  "tokenCount": 352,
  "systemPrompt": "",
  "messages": [
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "Hi!"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "senderInfo": {
            "senderName": "qwen2.5-coder-14b-instruct"
          },
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1738533933019-0.7230629863583222",
              "content": [
                {
                  "type": "text",
                  "text": "Hello! How can I assist you today? Feel free to ask me any questions or let me know if there's anything you'd like help with."
                }
              ],
              "genInfo": {
                "indexedModelIdentifier": "Qwen/Qwen2.5-Coder-14B-Instruct-GGUF/qwen2.5-coder-14b-instruct-q4_0.gguf",
                "identifier": "qwen2.5-coder-14b-instruct",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.llama.cpuThreadPoolSize",
                      "value": 6
                    },
                    {
                      "key": "llm.load.contextLength",
                      "value": 10096
                    },
                    {
                      "key": "llm.load.llama.acceleration.offloadRatio",
                      "value": 1
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
                          "bosToken": "<|endoftext|>",
                          "eosToken": "<|im_end|>",
                          "inputConfig": {
                            "messagesConfig": {
                              "contentConfig": {
                                "type": "string"
                              }
                            },
                            "useTools": false
                          }
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.llama.cpuThreads",
                      "value": 6
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 12.005781984603784,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 1.251,
                  "promptTokensCount": 31,
                  "predictedTokensCount": 30,
                  "totalTokensCount": 61
                }
              },
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true,
              "style": {
                "type": "default"
              }
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1738533935321-0.9367292189695944",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "Who is Andrej Karpathy?"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "senderInfo": {
            "senderName": "qwen2.5-coder-14b-instruct"
          },
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1738533971014-0.8593752170705797",
              "content": [
                {
                  "type": "text",
                  "text": "Andrej Karpathy is a prominent figure in the field of artificial intelligence and machine learning. He is currently the Director of AI at Tesla, Inc., where he leads the team responsible for advancing AI capabilities within the company. Prior to his role at Tesla, Karpathy was an assistant professor at Stanford University, where he taught courses on deep learning and computer vision.\n\nKarpathy is well-known for his contributions to open-source software in machine learning, particularly his work on the popular neural network framework TensorFlow. He has also been involved in research and development of various AI technologies, including image recognition systems and natural language processing models.\n\nIn addition to his technical expertise, Karpathy is recognized for his ability to communicate complex ideas clearly and inspire others in the field. He often speaks at conferences and writes about AI on his blog and Twitter, sharing insights and updates from his work at Tesla."
                }
              ],
              "genInfo": {
                "indexedModelIdentifier": "Qwen/Qwen2.5-Coder-14B-Instruct-GGUF/qwen2.5-coder-14b-instruct-q4_0.gguf",
                "identifier": "qwen2.5-coder-14b-instruct",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.llama.cpuThreadPoolSize",
                      "value": 6
                    },
                    {
                      "key": "llm.load.contextLength",
                      "value": 10096
                    },
                    {
                      "key": "llm.load.llama.acceleration.offloadRatio",
                      "value": 1
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
                          "bosToken": "<|endoftext|>",
                          "eosToken": "<|im_end|>",
                          "inputConfig": {
                            "messagesConfig": {
                              "contentConfig": {
                                "type": "string"
                              }
                            },
                            "useTools": false
                          }
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.llama.cpuThreads",
                      "value": 6
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 11.046072361082452,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 0.691,
                  "promptTokensCount": 79,
                  "predictedTokensCount": 178,
                  "totalTokensCount": 257
                }
              },
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true,
              "style": {
                "type": "default"
              }
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1738533986969-0.11426502687866402",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "That's great! Thanks! "
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "senderInfo": {
            "senderName": "qwen2.5-coder-14b-instruct"
          },
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1738534053584-0.30835171977464837",
              "content": [
                {
                  "type": "text",
                  "text": "You're welcome! If you have any more questions or need further information, feel free to ask. I'm here to help!"
                }
              ],
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true,
              "style": {
                "type": "default"
              },
              "genInfo": {
                "indexedModelIdentifier": "Qwen/Qwen2.5-Coder-14B-Instruct-GGUF/qwen2.5-coder-14b-instruct-q4_0.gguf",
                "identifier": "qwen2.5-coder-14b-instruct",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.llama.cpuThreadPoolSize",
                      "value": 6
                    },
                    {
                      "key": "llm.load.contextLength",
                      "value": 10096
                    },
                    {
                      "key": "llm.load.llama.acceleration.offloadRatio",
                      "value": 1
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
                          "bosToken": "<|endoftext|>",
                          "eosToken": "<|im_end|>",
                          "inputConfig": {
                            "messagesConfig": {
                              "contentConfig": {
                                "type": "string"
                              }
                            },
                            "useTools": false
                          }
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.llama.cpuThreads",
                      "value": 6
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 9.390220735196497,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 2.012,
                  "promptTokensCount": 274,
                  "predictedTokensCount": 26,
                  "totalTokensCount": 300
                }
              }
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1738534056031-0.5604554840057794",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ]
        }
      ],
      "currentlySelected": 0
    }
  ],
  "usePerChatPredictionConfig": true,
  "perChatPredictionConfig": {
    "fields": []
  },
  "clientInput": "",
  "clientInputFiles": [],
  "userFilesSizeBytes": 0,
  "lastUsedModel": {
    "indexedModelIdentifier": "Qwen/Qwen2.5-Coder-14B-Instruct-GGUF/qwen2.5-coder-14b-instruct-q4_0.gguf",
    "identifier": "qwen2.5-coder-14b-instruct",
    "instanceLoadTimeConfig": {
      "fields": []
    },
    "instanceOperationTimeConfig": {
      "fields": []
    }
  },
  "notes": [],
  "plugins": [],
  "pluginConfigs": {},
  "looseFiles": []
}